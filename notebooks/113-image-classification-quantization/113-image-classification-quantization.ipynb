{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQc-wXjqrEuR"
      },
      "source": [
        "# Quantization of Image Classification Models\n",
        "\n",
        "This tutorial demostrates how to apply INT8 quantization to Image Classification model using [Post-training Optimization Tool API](../../compression/api/README.md). The Mobilenet V2 model trained on the ImageNet-tiny dataset from Torchvision is used as an example. The code of this tutorial is designed to be extandable to custom model and dataset. It consists of the following steps:\n",
        "- Install OpenVINO and required tools and packages using PIP manager\n",
        "- Prepare the model for quantization\n",
        "- Define data loading and accuracy validation functionality\n",
        "- Run optimization pipeline\n",
        "- Compare accuracy of the original and quantized models\n",
        "- Compare performance of the original and quantized models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cSNQWdbSyeo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from addict import Dict\n",
        "\n",
        "sys.path.append('../utils')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prepare dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " In this tutorial CIFAR10 will be used for quantization. It is downloaded inside DataLoader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set the data and model directories\n",
        "DATA_DIR = 'data'\n",
        "MODEL_DIR = 'model'\n",
        "\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-frbVLKrkmv"
      },
      "source": [
        "## Prepare the Model\n",
        "Model preparation stage has the following steps:\n",
        "- Download PyTorch model from Torchvision repository\n",
        "- Convert it to ONNX format\n",
        "- Run OpenVINO Model Optimizer tool to convert ONNX to OpenVINO Intermediate Representation (IR)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7i6dWUmhloy"
      },
      "outputs": [],
      "source": [
        "model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_mobilenetv2_x1_0\", pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "dummy_input = torch.randn(1, 3, 32, 32)\n",
        "\n",
        "onnx_model_path = Path(MODEL_DIR) / 'mobilenet_v2.onnx'\n",
        "ir_model_xml = onnx_model_path.with_suffix('.xml')\n",
        "ir_model_bin = onnx_model_path.with_suffix('.bin')\n",
        "\n",
        "torch.onnx.export(model, dummy_input, onnx_model_path, verbose=True)\n",
        "\n",
        "# Run OpenVINO Model Optimization tool to convert ONNX to OpenVINO IR\n",
        "!mo --framework=onnx --data_type=FP16 --input_shape=[1,3,32,32] -m $onnx_model_path  --output_dir $MODEL_DIR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynLvh8rNc2wv"
      },
      "source": [
        "## Define Data Loader\n",
        "At this step the `DataLoader` interface from POT API is implemented."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "dataset = CIFAR10(root=DATA_DIR, train=False, transform=transform, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DErQofk8tO6c"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torchvision'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-9db3de701a8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCIFAR10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from compression.api import Metric, DataLoader\n",
        "\n",
        "\n",
        "class CifarDataLoader(DataLoader):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        if not isinstance(config, Dict):\n",
        "            config = Dict(config)\n",
        "        super().__init__(config)\n",
        "        self.indexes, self.pictures, self.labels = self.load_data(dataset)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if index >= len(self):\n",
        "            raise IndexError\n",
        "\n",
        "        return (self.indexes[index], self.labels[index]), self.pictures[index].unsqueeze(0)\n",
        "\n",
        "    def load_data(self, dataset):\n",
        "        pictures, labels, indexes = [], [], []\n",
        "        \n",
        "        for idx, sample in enumerate(dataset):\n",
        "            pictures.append(sample[0])\n",
        "            labels.append(sample[1])\n",
        "            indexes.append(idx)\n",
        "\n",
        "        return indexes, pictures, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re9-YhbBddh3"
      },
      "source": [
        "## Define Accuracy Metric Calculation\n",
        "At this step the `Metric` interface for accuracy Top-1 metric is implemented. It is used for validating accuracy of quantized model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GB8L492ztZEC"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'Metric' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-80a0c40de26f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Custom implementation of classification accuracy metric.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Required methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Metric' is not defined"
          ]
        }
      ],
      "source": [
        "# Custom implementation of classification accuracy metric.\n",
        "\n",
        "class Accuracy(Metric):\n",
        "\n",
        "    # Required methods\n",
        "    def __init__(self, top_k=1):\n",
        "        super().__init__()\n",
        "        self._top_k = top_k\n",
        "        self._name = 'accuracy@top{}'.format(self._top_k)\n",
        "        self._matches = []\n",
        "\n",
        "    @property\n",
        "    def value(self):\n",
        "        \"\"\" Returns accuracy metric value for the last model output. \"\"\"\n",
        "        return {self._name: self._matches[-1]}\n",
        "\n",
        "    @property\n",
        "    def avg_value(self):\n",
        "        \"\"\" Returns accuracy metric value for all model outputs. \"\"\"\n",
        "        return {self._name: np.ravel(self._matches).mean()}\n",
        "\n",
        "    def update(self, output, target):\n",
        "        \"\"\" Updates prediction matches.\n",
        "        :param output: model output\n",
        "        :param target: annotations\n",
        "        \"\"\"\n",
        "        if len(output) > 1:\n",
        "            raise Exception('The accuracy metric cannot be calculated '\n",
        "                            'for a model with multiple outputs')\n",
        "        if isinstance(target, dict):\n",
        "            target = list(target.values())\n",
        "        predictions = np.argsort(output[0], axis=1)[:, -self._top_k:]\n",
        "        match = [float(t in predictions[i]) for i, t in enumerate(target)]\n",
        "\n",
        "        self._matches.append(match)\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\" Resets collected matches \"\"\"\n",
        "        self._matches = []\n",
        "\n",
        "    def get_attributes(self):\n",
        "        \"\"\"\n",
        "        Returns a dictionary of metric attributes {metric_name: {attribute_name: value}}.\n",
        "        Required attributes: 'direction': 'higher-better' or 'higher-worse'\n",
        "                             'type': metric type\n",
        "        \"\"\"\n",
        "        return {self._name: {'direction': 'higher-better',\n",
        "                             'type': 'accuracy'}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CclWk-fVd9Wi"
      },
      "source": [
        "## Run Quantization Pipeline and compare the accuracy of the original and quantized models\n",
        "Here we define a configuration for our quantization pipeline and run it. \n",
        "\n",
        "**Note**: we use built-in `IEEngine` implementation of the `Engine` interface from the POT API for model inference. `IEEngine` is built on top of OpenVINO Python* API for inference and provides basic functionality for inference of simple models, ImageNet pre-trained models. If you have a more complicated inference flow for your model/models you should create your own implementation of `Engine` interface, for example by inheriting from `IEEngine` and extending it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiAvrwo0tr6Z"
      },
      "outputs": [],
      "source": [
        "from compression.graph import load_model, save_model\n",
        "from compression.graph.model_utils import compress_model_weights\n",
        "from compression.engines.ie_engine import IEEngine\n",
        "from compression.pipeline.initializer import create_pipeline\n",
        "\n",
        "model_config = Dict({\n",
        "    'model_name': 'mobilenet_v2',\n",
        "    'model': ir_model_xml,\n",
        "    'weights': ir_model_bin\n",
        "})\n",
        "engine_config = Dict({\n",
        "    'device': 'CPU',\n",
        "    'stat_requests_number': 2,\n",
        "    'eval_requests_number': 2\n",
        "})\n",
        "dataset_config = {\n",
        "    'data_source': DATA_DIR\n",
        "}\n",
        "algorithms = [\n",
        "    {\n",
        "        'name': 'DefaultQuantization',\n",
        "        'params': {\n",
        "            'target_device': 'CPU',\n",
        "            'preset': 'performance',\n",
        "            'stat_subset_size': 300\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "# Steps 1-7: Model optimization\n",
        "# Step 1: Load the model.\n",
        "model = load_model(model_config)\n",
        "\n",
        "# Step 2: Initialize the data loader.\n",
        "data_loader = CifarDataLoader(dataset_config)\n",
        "\n",
        "# Step 3 (Optional. Required for AccuracyAwareQuantization): Initialize the metric.\n",
        "metric = Accuracy(top_k=1)\n",
        "\n",
        "# Step 4: Initialize the engine for metric calculation and statistics collection.\n",
        "engine = IEEngine(engine_config, data_loader, metric)\n",
        "\n",
        "# Step 5: Create a pipeline of compression algorithms.\n",
        "pipeline = create_pipeline(algorithms, engine)\n",
        "\n",
        "# Step 6: Execute the pipeline.\n",
        "compressed_model = pipeline.run(model)\n",
        "\n",
        "# Step 7 (Optional): Compress model weights quantized precision\n",
        "#                    in order to reduce the size of final .bin file.\n",
        "compress_model_weights(compressed_model)\n",
        "\n",
        "# Step 8: Save the compressed model to the desired path.\n",
        "compressed_model_paths = save_model(model=compressed_model, save_path=MODEL_DIR, model_name=\"quantized_mobilenet_v2\"\n",
        ")\n",
        "compressed_model_xml = compressed_model_paths[0][\"model\"]\n",
        "\n",
        "# Step 9: Compare accuracy of the original and quantized models.\n",
        "metric_results = pipeline.evaluate(model)\n",
        "if metric_results:\n",
        "    for name, value in metric_results.items():\n",
        "        print('Accuracy of the original model: {: <27s}: {}'.format(name, value))\n",
        "\n",
        "metric_results = pipeline.evaluate(compressed_model)\n",
        "if metric_results:\n",
        "    for name, value in metric_results.items():\n",
        "        print('Accuracy of the optimized model: {: <27s}: {}'.format(name, value))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQACMfAUo52V"
      },
      "source": [
        "## Compare Performance of the Original and Quantized Models\n",
        "\n",
        "Finally, we will measure the inference performance of the FP32 and INT8 models. To do this, we use [Benchmark Tool](https://docs.openvinotoolkit.org/latest/openvino_inference_engine_tools_benchmark_tool_README.html) - OpenVINO's inference performance measurement tool.\n",
        "\n",
        "NOTE: For more accurate performance, we recommended running benchmark_app in a terminal/command prompt after closing other applications. Run benchmark_app -m model.xml -d CPU to benchmark async inference on CPU for one minute. Change CPU to GPU to benchmark on GPU. Run benchmark_app --help to see an overview of all command line options.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pC0gnO0c9-tI"
      },
      "outputs": [],
      "source": [
        "# Inference FP16 model (IR)\n",
        "!benchmark_app -m $ir_model_xml -d CPU -api async"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VR3-joFu9hH"
      },
      "outputs": [],
      "source": [
        "# Inference INT8 model (IR)\n",
        "!benchmark_app -m $compressed_model_xml -d CPU -api async"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "tutorial_tiny.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
