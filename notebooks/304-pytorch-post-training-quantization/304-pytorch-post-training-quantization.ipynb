{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-Training Quantization by NNCF\n",
    "\n",
    "This notebook is based on 'ImageNet training in PyTorch' example.\n",
    "\n",
    "The goal of this notebook is to demonstrate how to use the Neural Network Compression Framework NNCF 8-bit quantization to optimize a PyTorch model for inference with OpenVINO Toolkit. The optimization process contains the following steps:\n",
    "\n",
    "1. Evaluate the original model\n",
    "2. Transform the original model to a quantizaed one\n",
    "3. Export optimized and original models to ONNX\n",
    "4. Compare perfomance of obtained FP32 and INT8 ONNXs\n",
    "\n",
    "NOTE: This notebook requires C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On Windows, add the directory that contains cl.exe to the PATH to enable PyTorch to find the\n",
    "# required C++ tools. This code assumes that Visual Studio 2019 is installed in the default\n",
    "# directory. If you have a different C++ compiler, please add the correct path to os.environ[\"PATH\"]\n",
    "# directly.\n",
    "\n",
    "# Adding the path to os.environ[\"LIB\"] is not always required - it depends on the system's configuration\n",
    "\n",
    "import sys\n",
    "\n",
    "if sys.platform == \"win32\":\n",
    "    import distutils.command.build_ext\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "\n",
    "    VS_INSTALL_DIR = r\"C:/Program Files (x86)/Microsoft Visual Studio\"\n",
    "    cl_paths = sorted(list(Path(VS_INSTALL_DIR).glob(\"**/Hostx86/x64/cl.exe\")))\n",
    "    if len(cl_paths) == 0:\n",
    "        raise ValueError(\n",
    "            \"Cannot find Visual Studio. This notebook requires C++. If you installed \"\n",
    "            \"a C++ compiler, please add the directory that contains cl.exe to \"\n",
    "            \"`os.environ['PATH']`\"\n",
    "        )\n",
    "    else:\n",
    "        # If multiple versions of MSVC are installed, get the most recent version\n",
    "        cl_path = cl_paths[-1]\n",
    "        vs_dir = str(cl_path.parent)\n",
    "        os.environ[\"PATH\"] += f\"{os.pathsep}{vs_dir}\"\n",
    "        # Code for finding the library dirs from\n",
    "        # https://stackoverflow.com/questions/47423246/get-pythons-lib-path\n",
    "        d = distutils.core.Distribution()\n",
    "        b = distutils.command.build_ext.build_ext(d)\n",
    "        b.finalize_options()\n",
    "        os.environ[\"LIB\"] = os.pathsep.join(b.library_dirs)\n",
    "        print(f\"Added {vs_dir} to PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.6 of module 'openvino.inference_engine.ie_api' does not match runtime version 3.7\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.6 of module 'openvino.inference_engine.constants' does not match runtime version 3.7\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "810b95909fc440489e1fc4a6e698644b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model/resnet50_fp32.pth:   0%|          | 0.00/91.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/aleksei/nncf_work/openvino_notebooks/notebooks/304-pytorch-post-training-quantization/model/resnet50_fp32.pth')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "sys.path.append(\"../utils\")\n",
    "from notebook_utils import download_file\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using {device} device')\n",
    "\n",
    "MODEL_DIR = Path('model')\n",
    "OUTPUT_DIR = Path('output')\n",
    "BASE_MODEL_NAME = 'resnet50'\n",
    "IMAGE_SIZE = [64, 64]\n",
    "\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Paths where PyTorch, ONNX and will be stored\n",
    "fp32_checkpoint_filename = Path(BASE_MODEL_NAME + '_fp32').with_suffix('.pth') \n",
    "fp32_onnx_path = Path(OUTPUT_DIR / (BASE_MODEL_NAME + '_fp32')).with_suffix(\".onnx\")\n",
    "int8_onnx_path = Path(OUTPUT_DIR / (BASE_MODEL_NAME + '_int8')).with_suffix('.onnx') \n",
    "\n",
    "fp32_pth_url  = \"https://storage.openvinotoolkit.org/repositories/nncf/openvino_notebook_ckpts/304_resnet50_fp32.pth\"\n",
    "download_file(fp32_pth_url, directory=MODEL_DIR, filename=fp32_checkpoint_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and Prepare Tiny ImageNet dataset\n",
    "\n",
    "* 100k images of shape 3x64x64\n",
    "* 200 different classes: snake, spider, cat, truck, grasshopper, gull, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_tiny_imagenet_200(output_dir,\n",
    "                               url='http://cs231n.stanford.edu/tiny-imagenet-200.zip',\n",
    "                               tarname='tiny-imagenet-200.zip'):\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    archive_path = output_dir / tarname\n",
    "    download_file(url, directory=output_dir, filename=tarname)\n",
    "    zip_ref = zipfile.ZipFile(archive_path, 'r')\n",
    "    zip_ref.extractall(path=output_dir)\n",
    "    zip_ref.close()\n",
    "    print(f'Successfully downloaded and extracted dataset to: {output_dir}')\n",
    "\n",
    "def create_validation_dir(dataset_dir):\n",
    "    VALID_DIR = dataset_dir / 'val'\n",
    "    val_img_dir = VALID_DIR / 'images'\n",
    "    \n",
    "    fp = open(VALID_DIR / 'val_annotations.txt', 'r')\n",
    "    data = fp.readlines()\n",
    "    \n",
    "    val_img_dict = {}\n",
    "    for line in data:\n",
    "        words = line.split('\\t')\n",
    "        val_img_dict[words[0]] = words[1] \n",
    "    fp.close()\n",
    "    \n",
    "    for img, folder in val_img_dict.items():\n",
    "        newpath = val_img_dir/ folder\n",
    "        if not newpath.exists():\n",
    "            os.makedirs(newpath)\n",
    "        if (val_img_dir/ img).exists():\n",
    "            os.rename(val_img_dir/ img, newpath/ img)\n",
    "    \n",
    "DATASET_DIR = OUTPUT_DIR / 'tiny-imagenet-200'\n",
    "if not DATASET_DIR.exists():\n",
    "    download_tiny_imagenet_200(OUTPUT_DIR)\n",
    "    create_validation_dir(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers classes and functions\n",
    "These will help us to count accuracy and visualize validation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model):\n",
    "    batch_time = AverageMeter('Time', ':3.3f')\n",
    "    top1 = AverageMeter('Acc@1', ':2.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':2.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "            \n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            \n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            print_frequency = 10\n",
    "            if i % print_frequency == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and load original uncompressed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_path):\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    # update the last FC layer for Tiny ImageNet number of classes\n",
    "    NUM_CLASSES = 200\n",
    "    model.fc = nn.Linear(in_features=2048, out_features=NUM_CLASSES, bias=True)\n",
    "    model.to(device)\n",
    "    if model_path.exists():\n",
    "        checkpoint = torch.load(str(model_path), map_location='cpu')\n",
    "        model.load_state_dict(checkpoint['state_dict'], strict=True)\n",
    "    else:\n",
    "        raise RuntimeEror('There is no checkpoint to load')\n",
    "    return model\n",
    "\n",
    "model = create_model(MODEL_DIR / fp32_checkpoint_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train and validation dataloaders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(batch_size=128):\n",
    "    train_dir = DATASET_DIR / 'train'\n",
    "    val_dir = DATASET_DIR / 'val' / 'images'\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                      std=[0.229, 0.224, 0.225])\n",
    "    train_dataset = datasets.ImageFolder(\n",
    "    train_dir,\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "    val_dataset = datasets.ImageFolder(\n",
    "        val_dir,\n",
    "        transforms.Compose([\n",
    "            transforms.Resize(IMAGE_SIZE),\n",
    "            transforms.ToTensor(),\n",
    "            normalize\n",
    "        ]))\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True,\n",
    "    num_workers=4, pin_memory=True, sampler=None)\n",
    "    \n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False,\n",
    "        num_workers=4, pin_memory=True)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "train_loader, val_loader = create_dataloaders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Evaluate the loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [ 0/79]\tTime 0.475 (0.475)\tAcc@1 83.59 (83.59)\tAcc@5 93.75 (93.75)\n",
      "Test: [10/79]\tTime 0.272 (0.286)\tAcc@1 56.25 (67.19)\tAcc@5 85.16 (88.00)\n",
      "Test: [20/79]\tTime 0.265 (0.278)\tAcc@1 68.75 (64.40)\tAcc@5 84.38 (87.39)\n",
      "Test: [30/79]\tTime 0.266 (0.278)\tAcc@1 53.12 (62.83)\tAcc@5 76.56 (85.41)\n",
      "Test: [40/79]\tTime 0.267 (0.275)\tAcc@1 66.41 (61.22)\tAcc@5 89.84 (84.51)\n",
      "Test: [50/79]\tTime 0.265 (0.275)\tAcc@1 63.28 (61.04)\tAcc@5 88.28 (84.38)\n",
      "Test: [60/79]\tTime 0.268 (0.273)\tAcc@1 66.41 (60.80)\tAcc@5 87.50 (83.82)\n",
      "Test: [70/79]\tTime 0.256 (0.273)\tAcc@1 50.00 (60.50)\tAcc@5 78.91 (83.37)\n",
      " * Acc@1 61.040 Acc@5 83.990\n",
      "Test accuracy of FP32 model: 61.040\n"
     ]
    }
   ],
   "source": [
    "acc1 = validate(val_loader, model)\n",
    "print(f'Test accuracy of FP32 model: {acc1:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the FP32 model to ONNX, which is supported by OpenVINO™ Toolkit, to benchmark it in comparison with the INT8 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP32 ONNX model was exported to output/resnet50_fp32.onnx.\n"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.randn(1, 3, *IMAGE_SIZE).to(device)\n",
    "torch.onnx.export(model, dummy_input, fp32_onnx_path)\n",
    "print(f\"FP32 ONNX model was exported to {fp32_onnx_path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Create and initialize quantization\n",
    "NNCF enables post-training quantization using trainig dataset for the initialization process of recently added quantization layers. The framework is designed so that modifications to your original training code are minor. Quantization is the simplest scenario and requires only 3 modifications.\n",
    "\n",
    "### 1. Configure NNCF parameters to specify compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-12 14:45:17.514927: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "/home/aleksei/nncf_work/nncf_pytorch/nncf/torch/__init__.py:26: UserWarning: NNCF provides best results with torch==1.8.1, while current torch version is 1.7.0 - consider switching to torch==1.8.1\n",
      "  curr=torch.__version__\n"
     ]
    }
   ],
   "source": [
    "import nncf\n",
    "from nncf import NNCFConfig\n",
    "from nncf.torch import create_compressed_model\n",
    "from nncf.torch import register_default_init_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: update NNCF config to config with preset with per-channel quantization\n",
    "nncf_config_dict = {\n",
    "    \"input_info\": {\n",
    "        \"sample_size\": [1, 3, *IMAGE_SIZE]\n",
    "    },\n",
    "    \"log_dir\": str(OUTPUT_DIR), # log directory for NNCF-specific logging outputs\n",
    "    \"compression\": {\n",
    "        \"algorithm\": \"quantization\",\n",
    "        \"initializer\": {\n",
    "            \"range\": {\n",
    "                \"num_init_samples\": 15000\n",
    "            },\n",
    "            \"batchnorm_adaptation\": {\n",
    "                \"num_bn_adaptation_samples\": 4000\n",
    "            }\n",
    "        },\n",
    "        \"weights\": {\n",
    "            \"per_channel\": False\n",
    "        },\n",
    "        \"activations\": {\n",
    "            \"per_channel\": False\n",
    "        },\n",
    "        \"export_to_onnx_standard_ops\": True\n",
    "    }\n",
    "}\n",
    "nncf_config = NNCFConfig.from_dict(nncf_config_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Provide data loader to initialize the values of quantization ranges and determine which activation should be signed or unsigned from the collected statistics using a given number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:Please, provide execution parameters for optimal model initialization\n"
     ]
    }
   ],
   "source": [
    "nncf_config = register_default_init_args(nncf_config, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create a wrapped model ready for compression fine-tuning from a pre-trained FP32 model and configuration object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:Wrapping module ResNet/Conv2d[conv1] by ResNet/NNCFConv2d[conv1]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer1]/Bottleneck[0]/Conv2d[conv1] by ResNet/Sequential[layer1]/Bottleneck[0]/NNCFConv2d[conv1]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer1]/Bottleneck[0]/Conv2d[conv2] by ResNet/Sequential[layer1]/Bottleneck[0]/NNCFConv2d[conv2]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer1]/Bottleneck[0]/Conv2d[conv3] by ResNet/Sequential[layer1]/Bottleneck[0]/NNCFConv2d[conv3]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer1]/Bottleneck[0]/Sequential[downsample]/Conv2d[0] by ResNet/Sequential[layer1]/Bottleneck[0]/Sequential[downsample]/NNCFConv2d[0]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer1]/Bottleneck[1]/Conv2d[conv1] by ResNet/Sequential[layer1]/Bottleneck[1]/NNCFConv2d[conv1]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer1]/Bottleneck[1]/Conv2d[conv2] by ResNet/Sequential[layer1]/Bottleneck[1]/NNCFConv2d[conv2]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer1]/Bottleneck[1]/Conv2d[conv3] by ResNet/Sequential[layer1]/Bottleneck[1]/NNCFConv2d[conv3]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer1]/Bottleneck[2]/Conv2d[conv1] by ResNet/Sequential[layer1]/Bottleneck[2]/NNCFConv2d[conv1]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer1]/Bottleneck[2]/Conv2d[conv2] by ResNet/Sequential[layer1]/Bottleneck[2]/NNCFConv2d[conv2]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer1]/Bottleneck[2]/Conv2d[conv3] by ResNet/Sequential[layer1]/Bottleneck[2]/NNCFConv2d[conv3]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer2]/Bottleneck[0]/Conv2d[conv1] by ResNet/Sequential[layer2]/Bottleneck[0]/NNCFConv2d[conv1]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer2]/Bottleneck[0]/Conv2d[conv2] by ResNet/Sequential[layer2]/Bottleneck[0]/NNCFConv2d[conv2]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer2]/Bottleneck[0]/Conv2d[conv3] by ResNet/Sequential[layer2]/Bottleneck[0]/NNCFConv2d[conv3]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer2]/Bottleneck[0]/Sequential[downsample]/Conv2d[0] by ResNet/Sequential[layer2]/Bottleneck[0]/Sequential[downsample]/NNCFConv2d[0]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer2]/Bottleneck[1]/Conv2d[conv1] by ResNet/Sequential[layer2]/Bottleneck[1]/NNCFConv2d[conv1]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer2]/Bottleneck[1]/Conv2d[conv2] by ResNet/Sequential[layer2]/Bottleneck[1]/NNCFConv2d[conv2]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer2]/Bottleneck[1]/Conv2d[conv3] by ResNet/Sequential[layer2]/Bottleneck[1]/NNCFConv2d[conv3]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer2]/Bottleneck[2]/Conv2d[conv1] by ResNet/Sequential[layer2]/Bottleneck[2]/NNCFConv2d[conv1]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer2]/Bottleneck[2]/Conv2d[conv2] by ResNet/Sequential[layer2]/Bottleneck[2]/NNCFConv2d[conv2]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer2]/Bottleneck[2]/Conv2d[conv3] by ResNet/Sequential[layer2]/Bottleneck[2]/NNCFConv2d[conv3]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer2]/Bottleneck[3]/Conv2d[conv1] by ResNet/Sequential[layer2]/Bottleneck[3]/NNCFConv2d[conv1]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer2]/Bottleneck[3]/Conv2d[conv2] by ResNet/Sequential[layer2]/Bottleneck[3]/NNCFConv2d[conv2]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer2]/Bottleneck[3]/Conv2d[conv3] by ResNet/Sequential[layer2]/Bottleneck[3]/NNCFConv2d[conv3]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer3]/Bottleneck[0]/Conv2d[conv1] by ResNet/Sequential[layer3]/Bottleneck[0]/NNCFConv2d[conv1]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer3]/Bottleneck[0]/Conv2d[conv2] by ResNet/Sequential[layer3]/Bottleneck[0]/NNCFConv2d[conv2]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer3]/Bottleneck[0]/Conv2d[conv3] by ResNet/Sequential[layer3]/Bottleneck[0]/NNCFConv2d[conv3]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer3]/Bottleneck[0]/Sequential[downsample]/Conv2d[0] by ResNet/Sequential[layer3]/Bottleneck[0]/Sequential[downsample]/NNCFConv2d[0]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer3]/Bottleneck[1]/Conv2d[conv1] by ResNet/Sequential[layer3]/Bottleneck[1]/NNCFConv2d[conv1]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer3]/Bottleneck[1]/Conv2d[conv2] by ResNet/Sequential[layer3]/Bottleneck[1]/NNCFConv2d[conv2]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer3]/Bottleneck[1]/Conv2d[conv3] by ResNet/Sequential[layer3]/Bottleneck[1]/NNCFConv2d[conv3]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer3]/Bottleneck[2]/Conv2d[conv1] by ResNet/Sequential[layer3]/Bottleneck[2]/NNCFConv2d[conv1]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer3]/Bottleneck[2]/Conv2d[conv2] by ResNet/Sequential[layer3]/Bottleneck[2]/NNCFConv2d[conv2]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer3]/Bottleneck[2]/Conv2d[conv3] by ResNet/Sequential[layer3]/Bottleneck[2]/NNCFConv2d[conv3]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer3]/Bottleneck[3]/Conv2d[conv1] by ResNet/Sequential[layer3]/Bottleneck[3]/NNCFConv2d[conv1]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer3]/Bottleneck[3]/Conv2d[conv2] by ResNet/Sequential[layer3]/Bottleneck[3]/NNCFConv2d[conv2]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer3]/Bottleneck[3]/Conv2d[conv3] by ResNet/Sequential[layer3]/Bottleneck[3]/NNCFConv2d[conv3]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer3]/Bottleneck[4]/Conv2d[conv1] by ResNet/Sequential[layer3]/Bottleneck[4]/NNCFConv2d[conv1]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer3]/Bottleneck[4]/Conv2d[conv2] by ResNet/Sequential[layer3]/Bottleneck[4]/NNCFConv2d[conv2]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer3]/Bottleneck[4]/Conv2d[conv3] by ResNet/Sequential[layer3]/Bottleneck[4]/NNCFConv2d[conv3]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer3]/Bottleneck[5]/Conv2d[conv1] by ResNet/Sequential[layer3]/Bottleneck[5]/NNCFConv2d[conv1]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer3]/Bottleneck[5]/Conv2d[conv2] by ResNet/Sequential[layer3]/Bottleneck[5]/NNCFConv2d[conv2]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer3]/Bottleneck[5]/Conv2d[conv3] by ResNet/Sequential[layer3]/Bottleneck[5]/NNCFConv2d[conv3]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer4]/Bottleneck[0]/Conv2d[conv1] by ResNet/Sequential[layer4]/Bottleneck[0]/NNCFConv2d[conv1]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer4]/Bottleneck[0]/Conv2d[conv2] by ResNet/Sequential[layer4]/Bottleneck[0]/NNCFConv2d[conv2]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer4]/Bottleneck[0]/Conv2d[conv3] by ResNet/Sequential[layer4]/Bottleneck[0]/NNCFConv2d[conv3]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer4]/Bottleneck[0]/Sequential[downsample]/Conv2d[0] by ResNet/Sequential[layer4]/Bottleneck[0]/Sequential[downsample]/NNCFConv2d[0]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer4]/Bottleneck[1]/Conv2d[conv1] by ResNet/Sequential[layer4]/Bottleneck[1]/NNCFConv2d[conv1]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer4]/Bottleneck[1]/Conv2d[conv2] by ResNet/Sequential[layer4]/Bottleneck[1]/NNCFConv2d[conv2]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer4]/Bottleneck[1]/Conv2d[conv3] by ResNet/Sequential[layer4]/Bottleneck[1]/NNCFConv2d[conv3]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer4]/Bottleneck[2]/Conv2d[conv1] by ResNet/Sequential[layer4]/Bottleneck[2]/NNCFConv2d[conv1]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer4]/Bottleneck[2]/Conv2d[conv2] by ResNet/Sequential[layer4]/Bottleneck[2]/NNCFConv2d[conv2]\n",
      "INFO:nncf:Wrapping module ResNet/Sequential[layer4]/Bottleneck[2]/Conv2d[conv3] by ResNet/Sequential[layer4]/Bottleneck[2]/NNCFConv2d[conv3]\n",
      "INFO:nncf:Wrapping module ResNet/Linear[fc] by ResNet/NNCFLinear[fc]\n",
      "WARNING:nncf:NNCFNetwork(\n",
      "  (nncf_module): ResNet(\n",
      "    (conv1): NNCFConv2d(\n",
      "      3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "      (pre_ops): ModuleDict()\n",
      "      (post_ops): ModuleDict()\n",
      "    )\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): NNCFConv2d(\n",
      "          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): NNCFConv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): NNCFConv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): NNCFConv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (pre_ops): ModuleDict()\n",
      "            (post_ops): ModuleDict()\n",
      "          )\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): NNCFConv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): NNCFConv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): NNCFConv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): NNCFConv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): NNCFConv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): NNCFConv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): NNCFConv2d(\n",
      "          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): NNCFConv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): NNCFConv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): NNCFConv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (pre_ops): ModuleDict()\n",
      "            (post_ops): ModuleDict()\n",
      "          )\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): NNCFConv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): NNCFConv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): NNCFConv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): NNCFConv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): NNCFConv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): NNCFConv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): NNCFConv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): NNCFConv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): NNCFConv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): NNCFConv2d(\n",
      "          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): NNCFConv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): NNCFConv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): NNCFConv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (pre_ops): ModuleDict()\n",
      "            (post_ops): ModuleDict()\n",
      "          )\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): NNCFConv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): NNCFConv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): NNCFConv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): NNCFConv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): NNCFConv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): NNCFConv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): NNCFConv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): NNCFConv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): NNCFConv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): NNCFConv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): NNCFConv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): NNCFConv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): NNCFConv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): NNCFConv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): NNCFConv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): NNCFConv2d(\n",
      "          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): NNCFConv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): NNCFConv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): NNCFConv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (pre_ops): ModuleDict()\n",
      "            (post_ops): ModuleDict()\n",
      "          )\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): NNCFConv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): NNCFConv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): NNCFConv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): NNCFConv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): NNCFConv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): NNCFConv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (pre_ops): ModuleDict()\n",
      "          (post_ops): ModuleDict()\n",
      "        )\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): NNCFLinear(\n",
      "      in_features=2048, out_features=200, bias=True\n",
      "      (pre_ops): ModuleDict()\n",
      "      (post_ops): ModuleDict()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:Collecting tensor statistics █                 | 13 / 118\n",
      "INFO:nncf:Collecting tensor statistics ███               | 26 / 118\n",
      "INFO:nncf:Collecting tensor statistics █████             | 39 / 118\n",
      "INFO:nncf:Collecting tensor statistics ███████           | 52 / 118\n",
      "INFO:nncf:Collecting tensor statistics ████████          | 65 / 118\n",
      "INFO:nncf:Collecting tensor statistics ██████████        | 78 / 118\n",
      "INFO:nncf:Collecting tensor statistics ████████████      | 91 / 118\n",
      "INFO:nncf:Collecting tensor statistics ██████████████    | 104 / 118\n",
      "INFO:nncf:Collecting tensor statistics ███████████████   | 117 / 118\n",
      "INFO:nncf:Collecting tensor statistics ████████████████  | 118 / 118\n",
      "INFO:nncf:Set sign: True and scale: [2.6400, ] for TargetType.OPERATOR_POST_HOOK /nncf_model_input_0\n",
      "INFO:nncf:Performing signed activation quantization for: TargetType.OPERATOR_POST_HOOK /nncf_model_input_0\n",
      "INFO:nncf:Set sign: False and scale: [1.3751, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer1]/Bottleneck[0]/ReLU[relu]/relu__0\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer1]/Bottleneck[0]/ReLU[relu]/relu__0\n",
      "INFO:nncf:Set sign: False and scale: [1.3301, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer1]/Bottleneck[0]/ReLU[relu]/relu__1\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer1]/Bottleneck[0]/ReLU[relu]/relu__1\n",
      "INFO:nncf:Set sign: True and scale: [1.4236, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer1]/Bottleneck[0]/BatchNorm2d[bn3]/batch_norm_0\n",
      "INFO:nncf:Performing signed activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer1]/Bottleneck[0]/BatchNorm2d[bn3]/batch_norm_0\n",
      "INFO:nncf:Set sign: True and scale: [3.0768, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer1]/Bottleneck[0]/Sequential[downsample]/BatchNorm2d[1]/batch_norm_0\n",
      "INFO:nncf:Performing signed activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer1]/Bottleneck[0]/Sequential[downsample]/BatchNorm2d[1]/batch_norm_0\n",
      "INFO:nncf:Set sign: False and scale: [1.3861, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer1]/Bottleneck[1]/ReLU[relu]/relu__0\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer1]/Bottleneck[1]/ReLU[relu]/relu__0\n",
      "INFO:nncf:Set sign: False and scale: [1.8079, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer1]/Bottleneck[1]/ReLU[relu]/relu__1\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer1]/Bottleneck[1]/ReLU[relu]/relu__1\n",
      "INFO:nncf:Set sign: True and scale: [1.3196, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer1]/Bottleneck[1]/BatchNorm2d[bn3]/batch_norm_0\n",
      "INFO:nncf:Performing signed activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer1]/Bottleneck[1]/BatchNorm2d[bn3]/batch_norm_0\n",
      "INFO:nncf:Set sign: False and scale: [1.3589, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer1]/Bottleneck[2]/ReLU[relu]/relu__0\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer1]/Bottleneck[2]/ReLU[relu]/relu__0\n",
      "INFO:nncf:Set sign: False and scale: [2.0299, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer1]/Bottleneck[2]/ReLU[relu]/relu__1\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer1]/Bottleneck[2]/ReLU[relu]/relu__1\n",
      "INFO:nncf:Set sign: True and scale: [2.1641, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer1]/Bottleneck[2]/BatchNorm2d[bn3]/batch_norm_0\n",
      "INFO:nncf:Performing signed activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer1]/Bottleneck[2]/BatchNorm2d[bn3]/batch_norm_0\n",
      "INFO:nncf:Set sign: False and scale: [2.0822, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer2]/Bottleneck[0]/ReLU[relu]/relu__0\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer2]/Bottleneck[0]/ReLU[relu]/relu__0\n",
      "INFO:nncf:Set sign: False and scale: [1.5979, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer2]/Bottleneck[0]/ReLU[relu]/relu__1\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer2]/Bottleneck[0]/ReLU[relu]/relu__1\n",
      "INFO:nncf:Set sign: True and scale: [2.5227, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer2]/Bottleneck[0]/BatchNorm2d[bn3]/batch_norm_0\n",
      "INFO:nncf:Performing signed activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer2]/Bottleneck[0]/BatchNorm2d[bn3]/batch_norm_0\n",
      "INFO:nncf:Set sign: True and scale: [2.1236, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer2]/Bottleneck[0]/Sequential[downsample]/BatchNorm2d[1]/batch_norm_0\n",
      "INFO:nncf:Performing signed activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer2]/Bottleneck[0]/Sequential[downsample]/BatchNorm2d[1]/batch_norm_0\n",
      "INFO:nncf:Set sign: False and scale: [1.0381, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer2]/Bottleneck[1]/ReLU[relu]/relu__0\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer2]/Bottleneck[1]/ReLU[relu]/relu__0\n",
      "INFO:nncf:Set sign: False and scale: [1.2998, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer2]/Bottleneck[1]/ReLU[relu]/relu__1\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer2]/Bottleneck[1]/ReLU[relu]/relu__1\n",
      "INFO:nncf:Set sign: True and scale: [2.2935, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer2]/Bottleneck[1]/BatchNorm2d[bn3]/batch_norm_0\n",
      "INFO:nncf:Performing signed activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer2]/Bottleneck[1]/BatchNorm2d[bn3]/batch_norm_0\n",
      "INFO:nncf:Set sign: False and scale: [1.4056, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer2]/Bottleneck[2]/ReLU[relu]/relu__0\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer2]/Bottleneck[2]/ReLU[relu]/relu__0\n",
      "INFO:nncf:Set sign: False and scale: [1.2988, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer2]/Bottleneck[2]/ReLU[relu]/relu__1\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer2]/Bottleneck[2]/ReLU[relu]/relu__1\n",
      "INFO:nncf:Set sign: True and scale: [1.7012, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer2]/Bottleneck[2]/BatchNorm2d[bn3]/batch_norm_0\n",
      "INFO:nncf:Performing signed activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer2]/Bottleneck[2]/BatchNorm2d[bn3]/batch_norm_0\n",
      "INFO:nncf:Set sign: False and scale: [1.5876, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer2]/Bottleneck[3]/ReLU[relu]/relu__0\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer2]/Bottleneck[3]/ReLU[relu]/relu__0\n",
      "INFO:nncf:Set sign: False and scale: [1.6066, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer2]/Bottleneck[3]/ReLU[relu]/relu__1\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer2]/Bottleneck[3]/ReLU[relu]/relu__1\n",
      "INFO:nncf:Set sign: True and scale: [1.6932, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer2]/Bottleneck[3]/BatchNorm2d[bn3]/batch_norm_0\n",
      "INFO:nncf:Performing signed activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer2]/Bottleneck[3]/BatchNorm2d[bn3]/batch_norm_0\n",
      "INFO:nncf:Set sign: False and scale: [2.4998, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[0]/ReLU[relu]/relu__0\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[0]/ReLU[relu]/relu__0\n",
      "INFO:nncf:Set sign: False and scale: [1.5909, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[0]/ReLU[relu]/relu__1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[0]/ReLU[relu]/relu__1\n",
      "INFO:nncf:Set sign: True and scale: [2.2700, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[0]/BatchNorm2d[bn3]/batch_norm_0\n",
      "INFO:nncf:Performing signed activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[0]/BatchNorm2d[bn3]/batch_norm_0\n",
      "INFO:nncf:Set sign: True and scale: [1.7111, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[0]/Sequential[downsample]/BatchNorm2d[1]/batch_norm_0\n",
      "INFO:nncf:Performing signed activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[0]/Sequential[downsample]/BatchNorm2d[1]/batch_norm_0\n",
      "INFO:nncf:Set sign: False and scale: [2.5322, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[1]/ReLU[relu]/relu__0\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[1]/ReLU[relu]/relu__0\n",
      "INFO:nncf:Set sign: False and scale: [2.6308, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[1]/ReLU[relu]/relu__1\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[1]/ReLU[relu]/relu__1\n",
      "INFO:nncf:Set sign: True and scale: [5.5854, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[1]/BatchNorm2d[bn3]/batch_norm_0\n",
      "INFO:nncf:Performing signed activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[1]/BatchNorm2d[bn3]/batch_norm_0\n",
      "INFO:nncf:Set sign: False and scale: [2.1899, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[2]/ReLU[relu]/relu__0\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[2]/ReLU[relu]/relu__0\n",
      "INFO:nncf:Set sign: False and scale: [2.0018, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[2]/ReLU[relu]/relu__1\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[2]/ReLU[relu]/relu__1\n",
      "INFO:nncf:Set sign: True and scale: [2.4872, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[2]/BatchNorm2d[bn3]/batch_norm_0\n",
      "INFO:nncf:Performing signed activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[2]/BatchNorm2d[bn3]/batch_norm_0\n",
      "INFO:nncf:Set sign: False and scale: [3.0003, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[3]/ReLU[relu]/relu__0\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[3]/ReLU[relu]/relu__0\n",
      "INFO:nncf:Set sign: False and scale: [2.5992, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[3]/ReLU[relu]/relu__1\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[3]/ReLU[relu]/relu__1\n",
      "INFO:nncf:Set sign: True and scale: [4.9621, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[3]/BatchNorm2d[bn3]/batch_norm_0\n",
      "INFO:nncf:Performing signed activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[3]/BatchNorm2d[bn3]/batch_norm_0\n",
      "INFO:nncf:Set sign: False and scale: [2.4053, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[4]/ReLU[relu]/relu__0\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[4]/ReLU[relu]/relu__0\n",
      "INFO:nncf:Set sign: False and scale: [1.9779, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[4]/ReLU[relu]/relu__1\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[4]/ReLU[relu]/relu__1\n",
      "INFO:nncf:Set sign: True and scale: [2.8914, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[4]/BatchNorm2d[bn3]/batch_norm_0\n",
      "INFO:nncf:Performing signed activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[4]/BatchNorm2d[bn3]/batch_norm_0\n",
      "INFO:nncf:Set sign: False and scale: [4.5207, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[5]/ReLU[relu]/relu__0\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[5]/ReLU[relu]/relu__0\n",
      "INFO:nncf:Set sign: False and scale: [4.0090, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[5]/ReLU[relu]/relu__1\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[5]/ReLU[relu]/relu__1\n",
      "INFO:nncf:Set sign: True and scale: [4.6444, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[5]/BatchNorm2d[bn3]/batch_norm_0\n",
      "INFO:nncf:Performing signed activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[5]/BatchNorm2d[bn3]/batch_norm_0\n",
      "INFO:nncf:Set sign: False and scale: [2.1239, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer4]/Bottleneck[0]/ReLU[relu]/relu__0\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer4]/Bottleneck[0]/ReLU[relu]/relu__0\n",
      "INFO:nncf:Set sign: False and scale: [1.6178, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer4]/Bottleneck[0]/ReLU[relu]/relu__1\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer4]/Bottleneck[0]/ReLU[relu]/relu__1\n",
      "INFO:nncf:Set sign: True and scale: [5.5252, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer4]/Bottleneck[0]/BatchNorm2d[bn3]/batch_norm_0\n",
      "INFO:nncf:Performing signed activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer4]/Bottleneck[0]/BatchNorm2d[bn3]/batch_norm_0\n",
      "INFO:nncf:Set sign: True and scale: [4.9000, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer4]/Bottleneck[0]/Sequential[downsample]/BatchNorm2d[1]/batch_norm_0\n",
      "INFO:nncf:Performing signed activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer4]/Bottleneck[0]/Sequential[downsample]/BatchNorm2d[1]/batch_norm_0\n",
      "INFO:nncf:Set sign: False and scale: [1.7831, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer4]/Bottleneck[1]/ReLU[relu]/relu__0\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer4]/Bottleneck[1]/ReLU[relu]/relu__0\n",
      "INFO:nncf:Set sign: False and scale: [1.5503, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer4]/Bottleneck[1]/ReLU[relu]/relu__1\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer4]/Bottleneck[1]/ReLU[relu]/relu__1\n",
      "INFO:nncf:Set sign: True and scale: [5.0126, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer4]/Bottleneck[1]/BatchNorm2d[bn3]/batch_norm_0\n",
      "INFO:nncf:Performing signed activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer4]/Bottleneck[1]/BatchNorm2d[bn3]/batch_norm_0\n",
      "INFO:nncf:Set sign: False and scale: [2.0293, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer4]/Bottleneck[2]/ReLU[relu]/relu__0\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer4]/Bottleneck[2]/ReLU[relu]/relu__0\n",
      "INFO:nncf:Set sign: False and scale: [1.7402, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer4]/Bottleneck[2]/ReLU[relu]/relu__1\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer4]/Bottleneck[2]/ReLU[relu]/relu__1\n",
      "INFO:nncf:Set sign: True and scale: [8.9805, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer4]/Bottleneck[2]/BatchNorm2d[bn3]/batch_norm_0\n",
      "INFO:nncf:Performing signed activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer4]/Bottleneck[2]/BatchNorm2d[bn3]/batch_norm_0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:Set sign: False and scale: [13.9028, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer4]/Bottleneck[2]/ReLU[relu]/relu__2\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer4]/Bottleneck[2]/ReLU[relu]/relu__2\n",
      "INFO:nncf:Set sign: False and scale: [11.9460, ] for TargetType.OPERATOR_POST_HOOK ResNet/AdaptiveAvgPool2d[avgpool]/adaptive_avg_pool2d_0\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/AdaptiveAvgPool2d[avgpool]/adaptive_avg_pool2d_0\n",
      "INFO:nncf:Set sign: False and scale: [3.1914, ] for TargetType.OPERATOR_POST_HOOK ResNet/ReLU[relu]/relu__0\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/ReLU[relu]/relu__0\n",
      "INFO:nncf:Set sign: False and scale: [2.4739, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer1]/Bottleneck[0]/ReLU[relu]/relu__2\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer1]/Bottleneck[0]/ReLU[relu]/relu__2\n",
      "INFO:nncf:Set sign: False and scale: [2.4844, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer1]/Bottleneck[1]/ReLU[relu]/relu__2\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer1]/Bottleneck[1]/ReLU[relu]/relu__2\n",
      "INFO:nncf:Set sign: False and scale: [2.5816, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer1]/Bottleneck[2]/ReLU[relu]/relu__2\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer1]/Bottleneck[2]/ReLU[relu]/relu__2\n",
      "INFO:nncf:Set sign: False and scale: [2.6012, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer2]/Bottleneck[0]/ReLU[relu]/relu__2\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer2]/Bottleneck[0]/ReLU[relu]/relu__2\n",
      "INFO:nncf:Set sign: False and scale: [2.5881, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer2]/Bottleneck[1]/ReLU[relu]/relu__2\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer2]/Bottleneck[1]/ReLU[relu]/relu__2\n",
      "INFO:nncf:Set sign: False and scale: [2.6351, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer2]/Bottleneck[2]/ReLU[relu]/relu__2\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer2]/Bottleneck[2]/ReLU[relu]/relu__2\n",
      "INFO:nncf:Set sign: False and scale: [2.8291, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer2]/Bottleneck[3]/ReLU[relu]/relu__2\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer2]/Bottleneck[3]/ReLU[relu]/relu__2\n",
      "INFO:nncf:Set sign: False and scale: [2.7775, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[0]/ReLU[relu]/relu__2\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[0]/ReLU[relu]/relu__2\n",
      "INFO:nncf:Set sign: False and scale: [6.2891, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[1]/ReLU[relu]/relu__2\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[1]/ReLU[relu]/relu__2\n",
      "INFO:nncf:Set sign: False and scale: [5.0808, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[2]/ReLU[relu]/relu__2\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[2]/ReLU[relu]/relu__2\n",
      "INFO:nncf:Set sign: False and scale: [6.0070, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[3]/ReLU[relu]/relu__2\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[3]/ReLU[relu]/relu__2\n",
      "INFO:nncf:Set sign: False and scale: [6.7952, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[4]/ReLU[relu]/relu__2\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[4]/ReLU[relu]/relu__2\n",
      "INFO:nncf:Set sign: False and scale: [3.6891, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[5]/ReLU[relu]/relu__2\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer3]/Bottleneck[5]/ReLU[relu]/relu__2\n",
      "INFO:nncf:Set sign: False and scale: [7.6461, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer4]/Bottleneck[0]/ReLU[relu]/relu__2\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer4]/Bottleneck[0]/ReLU[relu]/relu__2\n",
      "INFO:nncf:Set sign: False and scale: [9.0934, ] for TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer4]/Bottleneck[1]/ReLU[relu]/relu__2\n",
      "INFO:nncf:Performing unsigned activation quantization for: TargetType.OPERATOR_POST_HOOK ResNet/Sequential[layer4]/Bottleneck[1]/ReLU[relu]/relu__2\n",
      "WARNING:nncf:The saturation issue fix will be applied. Now all weight quantizers will effectively use only 7 bits out of 8 bits. This resolves the saturation issue problem on AVX2 and AVX-512 machines. Please take a look at the documentation for a detailed information.\n",
      "INFO:nncf:Set sign: True and scale: [0.7843, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/NNCFConv2d[conv1]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/NNCFConv2d[conv1]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.7401, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer1]/Bottleneck[0]/NNCFConv2d[conv1]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer1]/Bottleneck[0]/NNCFConv2d[conv1]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.4691, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer1]/Bottleneck[0]/NNCFConv2d[conv2]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer1]/Bottleneck[0]/NNCFConv2d[conv2]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.4013, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer1]/Bottleneck[0]/NNCFConv2d[conv3]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer1]/Bottleneck[0]/NNCFConv2d[conv3]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.9896, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer1]/Bottleneck[0]/Sequential[downsample]/NNCFConv2d[0]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer1]/Bottleneck[0]/Sequential[downsample]/NNCFConv2d[0]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.2734, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer1]/Bottleneck[1]/NNCFConv2d[conv1]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer1]/Bottleneck[1]/NNCFConv2d[conv1]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.5250, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer1]/Bottleneck[1]/NNCFConv2d[conv2]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer1]/Bottleneck[1]/NNCFConv2d[conv2]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.2937, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer1]/Bottleneck[1]/NNCFConv2d[conv3]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer1]/Bottleneck[1]/NNCFConv2d[conv3]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.1900, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer1]/Bottleneck[2]/NNCFConv2d[conv1]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer1]/Bottleneck[2]/NNCFConv2d[conv1]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.2812, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer1]/Bottleneck[2]/NNCFConv2d[conv2]/conv2d_0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer1]/Bottleneck[2]/NNCFConv2d[conv2]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.2867, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer1]/Bottleneck[2]/NNCFConv2d[conv3]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer1]/Bottleneck[2]/NNCFConv2d[conv3]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.3477, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer2]/Bottleneck[0]/NNCFConv2d[conv1]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer2]/Bottleneck[0]/NNCFConv2d[conv1]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.2922, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer2]/Bottleneck[0]/NNCFConv2d[conv2]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer2]/Bottleneck[0]/NNCFConv2d[conv2]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.3950, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer2]/Bottleneck[0]/NNCFConv2d[conv3]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer2]/Bottleneck[0]/NNCFConv2d[conv3]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.5627, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer2]/Bottleneck[0]/Sequential[downsample]/NNCFConv2d[0]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer2]/Bottleneck[0]/Sequential[downsample]/NNCFConv2d[0]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.2537, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer2]/Bottleneck[1]/NNCFConv2d[conv1]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer2]/Bottleneck[1]/NNCFConv2d[conv1]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.3070, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer2]/Bottleneck[1]/NNCFConv2d[conv2]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer2]/Bottleneck[1]/NNCFConv2d[conv2]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.2972, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer2]/Bottleneck[1]/NNCFConv2d[conv3]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer2]/Bottleneck[1]/NNCFConv2d[conv3]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.2340, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer2]/Bottleneck[2]/NNCFConv2d[conv1]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer2]/Bottleneck[2]/NNCFConv2d[conv1]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.2519, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer2]/Bottleneck[2]/NNCFConv2d[conv2]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer2]/Bottleneck[2]/NNCFConv2d[conv2]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.3606, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer2]/Bottleneck[2]/NNCFConv2d[conv3]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer2]/Bottleneck[2]/NNCFConv2d[conv3]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.2853, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer2]/Bottleneck[3]/NNCFConv2d[conv1]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer2]/Bottleneck[3]/NNCFConv2d[conv1]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.2528, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer2]/Bottleneck[3]/NNCFConv2d[conv2]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer2]/Bottleneck[3]/NNCFConv2d[conv2]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.3006, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer2]/Bottleneck[3]/NNCFConv2d[conv3]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer2]/Bottleneck[3]/NNCFConv2d[conv3]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.3453, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[0]/NNCFConv2d[conv1]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[0]/NNCFConv2d[conv1]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.2084, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[0]/NNCFConv2d[conv2]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[0]/NNCFConv2d[conv2]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.3305, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[0]/NNCFConv2d[conv3]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[0]/NNCFConv2d[conv3]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.3454, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[0]/Sequential[downsample]/NNCFConv2d[0]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[0]/Sequential[downsample]/NNCFConv2d[0]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.3043, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[1]/NNCFConv2d[conv1]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[1]/NNCFConv2d[conv1]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.2679, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[1]/NNCFConv2d[conv2]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[1]/NNCFConv2d[conv2]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.5046, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[1]/NNCFConv2d[conv3]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[1]/NNCFConv2d[conv3]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.2744, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[2]/NNCFConv2d[conv1]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[2]/NNCFConv2d[conv1]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.2145, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[2]/NNCFConv2d[conv2]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[2]/NNCFConv2d[conv2]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.3597, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[2]/NNCFConv2d[conv3]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[2]/NNCFConv2d[conv3]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.2501, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[3]/NNCFConv2d[conv1]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[3]/NNCFConv2d[conv1]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.2778, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[3]/NNCFConv2d[conv2]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[3]/NNCFConv2d[conv2]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.3187, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[3]/NNCFConv2d[conv3]/conv2d_0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[3]/NNCFConv2d[conv3]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.2772, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[4]/NNCFConv2d[conv1]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[4]/NNCFConv2d[conv1]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.1970, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[4]/NNCFConv2d[conv2]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[4]/NNCFConv2d[conv2]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.3223, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[4]/NNCFConv2d[conv3]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[4]/NNCFConv2d[conv3]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.3976, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[5]/NNCFConv2d[conv1]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[5]/NNCFConv2d[conv1]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.2225, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[5]/NNCFConv2d[conv2]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[5]/NNCFConv2d[conv2]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.3342, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[5]/NNCFConv2d[conv3]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer3]/Bottleneck[5]/NNCFConv2d[conv3]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.3432, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer4]/Bottleneck[0]/NNCFConv2d[conv1]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer4]/Bottleneck[0]/NNCFConv2d[conv1]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.4056, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer4]/Bottleneck[0]/NNCFConv2d[conv2]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer4]/Bottleneck[0]/NNCFConv2d[conv2]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.3490, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer4]/Bottleneck[0]/NNCFConv2d[conv3]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer4]/Bottleneck[0]/NNCFConv2d[conv3]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.6437, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer4]/Bottleneck[0]/Sequential[downsample]/NNCFConv2d[0]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer4]/Bottleneck[0]/Sequential[downsample]/NNCFConv2d[0]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.6899, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer4]/Bottleneck[1]/NNCFConv2d[conv1]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer4]/Bottleneck[1]/NNCFConv2d[conv1]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.2094, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer4]/Bottleneck[1]/NNCFConv2d[conv2]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer4]/Bottleneck[1]/NNCFConv2d[conv2]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.2367, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer4]/Bottleneck[1]/NNCFConv2d[conv3]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer4]/Bottleneck[1]/NNCFConv2d[conv3]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.4706, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer4]/Bottleneck[2]/NNCFConv2d[conv1]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer4]/Bottleneck[2]/NNCFConv2d[conv1]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.1354, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer4]/Bottleneck[2]/NNCFConv2d[conv2]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer4]/Bottleneck[2]/NNCFConv2d[conv2]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.2725, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer4]/Bottleneck[2]/NNCFConv2d[conv3]/conv2d_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/Sequential[layer4]/Bottleneck[2]/NNCFConv2d[conv3]/conv2d_0\n",
      "INFO:nncf:Set sign: True and scale: [0.1000, ] for TargetType.OPERATION_WITH_WEIGHTS ResNet/NNCFLinear[fc]/linear_0\n",
      "INFO:nncf:Performing signed weight quantization for: TargetType.OPERATION_WITH_WEIGHTS ResNet/NNCFLinear[fc]/linear_0\n",
      "INFO:nncf:BatchNorm statistics adaptation █                 | 3 / 32\n",
      "INFO:nncf:BatchNorm statistics adaptation ███               | 6 / 32\n",
      "INFO:nncf:BatchNorm statistics adaptation ████              | 9 / 32\n",
      "INFO:nncf:BatchNorm statistics adaptation ██████            | 12 / 32\n",
      "INFO:nncf:BatchNorm statistics adaptation ███████           | 15 / 32\n",
      "INFO:nncf:BatchNorm statistics adaptation █████████         | 18 / 32\n",
      "INFO:nncf:BatchNorm statistics adaptation ██████████        | 21 / 32\n",
      "INFO:nncf:BatchNorm statistics adaptation ████████████      | 24 / 32\n",
      "INFO:nncf:BatchNorm statistics adaptation █████████████     | 27 / 32\n",
      "INFO:nncf:BatchNorm statistics adaptation ███████████████   | 30 / 32\n",
      "INFO:nncf:BatchNorm statistics adaptation ████████████████  | 32 / 32\n"
     ]
    }
   ],
   "source": [
    "compression_ctrl, model = create_compressed_model(model, nncf_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate the new model on the validation set after initialization of quantization. The accuracy should be close to the accuracy of the floating-point FP32 model for a simple case like the one we are demonstrating now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [ 0/79]\tTime 0.654 (0.654)\tAcc@1 83.59 (83.59)\tAcc@5 92.97 (92.97)\n",
      "Test: [10/79]\tTime 0.385 (0.413)\tAcc@1 58.59 (66.41)\tAcc@5 86.72 (87.14)\n",
      "Test: [20/79]\tTime 0.384 (0.401)\tAcc@1 70.31 (64.06)\tAcc@5 85.16 (87.13)\n",
      "Test: [30/79]\tTime 0.381 (0.396)\tAcc@1 52.34 (62.02)\tAcc@5 75.78 (84.95)\n",
      "Test: [40/79]\tTime 0.387 (0.394)\tAcc@1 66.41 (60.50)\tAcc@5 85.94 (84.05)\n",
      "Test: [50/79]\tTime 0.384 (0.393)\tAcc@1 63.28 (60.75)\tAcc@5 86.72 (83.92)\n",
      "Test: [60/79]\tTime 0.391 (0.392)\tAcc@1 65.62 (60.37)\tAcc@5 87.50 (83.29)\n",
      "Test: [70/79]\tTime 0.376 (0.391)\tAcc@1 56.25 (60.16)\tAcc@5 79.69 (82.90)\n",
      " * Acc@1 60.660 Acc@5 83.520\n",
      "Accuracy of initialized INT8 model: 60.660\n"
     ]
    }
   ],
   "source": [
    "acc1 = validate(val_loader, model)\n",
    "print(f'Accuracy of initialized INT8 model: {acc1:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Export INT8 model to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aleksei/nncf_work/virtualenv/nncf_develop_python_3_7/lib/python3.7/site-packages/torch-1.7.0-py3.7-linux-x86_64.egg/torch/onnx/utils.py:299: UserWarning: It is recommended that constant folding be turned off ('do_constant_folding=False') when exporting the model in training-amenable mode, i.e. with 'training=TrainingMode.TRAIN' or 'training=TrainingMode.PRESERVE' (when model is in training mode). Otherwise, some learnable model parameters may not translate correctly in the exported ONNX model because constant folding mutates model parameters. Please consider turning off constant folding or setting the training=TrainingMode.EVAL.\n",
      "  warnings.warn(\"It is recommended that constant folding be turned off ('do_constant_folding=False') \"\n",
      "/home/aleksei/nncf_work/nncf_pytorch/nncf/torch/dynamic_graph/trace_tensor.py:36: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  self.shape = tuple(int(dim) for dim in shape)  # Handle cases when shape is a tuple of Tensors\n",
      "/home/aleksei/nncf_work/nncf_pytorch/nncf/torch/quantization/layers.py:148: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if not self.is_enabled_quantization():\n",
      "/home/aleksei/nncf_work/nncf_pytorch/nncf/torch/quantization/layers.py:204: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return self._num_bits.item()\n",
      "/home/aleksei/nncf_work/nncf_pytorch/nncf/torch/quantization/layers.py:414: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  return self.signed_tensor.item() == 1\n",
      "/home/aleksei/nncf_work/nncf_pytorch/nncf/torch/layers.py:100: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  self.get_padding_value_ref().data.fill_(padding_value.item())\n",
      "/home/aleksei/nncf_work/nncf_pytorch/nncf/torch/layers.py:106: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if not self.get_padding_value_ref():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INT8 ONNX model exported to output/resnet50_int8.onnx.\n"
     ]
    }
   ],
   "source": [
    "compression_ctrl.export_model(int8_onnx_path)\n",
    "print(f\"INT8 ONNX model exported to {int8_onnx_path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Compare perfomance of ONNX's INT8 model and FP32 model in OpenVINO Execution Provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import onnxruntime as rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def measure_perfomance(session, image_size, runs=10):\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    total = 0.0\n",
    "    input_data = np.zeros((1, 3, *IMAGE_SIZE), np.float32)\n",
    "    # Warming up\n",
    "    _ = session.run([], {input_name: input_data})\n",
    "    for i in range(runs):\n",
    "        start = time.perf_counter()\n",
    "        _ = session.run([], {input_name: input_data})\n",
    "        end = (time.perf_counter() - start) * 1000\n",
    "        total += end\n",
    "        \n",
    "    total /= runs\n",
    "    print(f\"Avg: {total:.2f}ms\")\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "['OpenVINOExecutionProvider'] does not contain a subset of available providers ['CPUExecutionProvider']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32699/3929753413.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInferenceSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp32_onnx_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_providers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'OpenVINOExecutionProvider'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfp32_inf_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeasure_perfomance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nncf_work/virtualenv/nncf_develop_python_3_7/lib/python3.7/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\u001b[0m in \u001b[0;36mset_providers\u001b[0;34m(self, providers, provider_options)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproviders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_available_providers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             raise ValueError(\"{} does not contain a subset of available providers {}\".format(\n\u001b[0;32m---> 70\u001b[0;31m                 providers, C.get_available_providers()))\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprovider_options\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: ['OpenVINOExecutionProvider'] does not contain a subset of available providers ['CPUExecutionProvider']"
     ]
    }
   ],
   "source": [
    "session = rt.InferenceSession(str(fp32_onnx_path))\n",
    "session.set_providers(['OpenVINOExecutionProvider'])\n",
    "fp32_inf_time = measure_perfomance(session, IMAGE_SIZE, runs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = rt.InferenceSession(str(int8_onnx_path))\n",
    "session.set_providers(['OpenVINOExecutionProvider'])\n",
    "int8_inf_time = measure_perfomance(session, IMAGE_SIZE, runs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_coefficient = fp32_inf_time / int8_inf_time\n",
    "print (f'Gain coefficient is = {gain_coefficient}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nncf_develop",
   "language": "python",
   "name": "nncf_develop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
